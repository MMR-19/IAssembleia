{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64fe1c66",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17316009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb4b6d",
   "metadata": {},
   "source": [
    "Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87594e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "deployment = \"gpt-4o-mini\"\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "# Load credentials from environment variable\n",
    "subscription_key = os.getenv(\"subscription_key\")\n",
    "if not subscription_key:\n",
    "    raise RuntimeError(\"subscription_key not found in environment variables\")\n",
    "\n",
    "endpoint = os.getenv(\"endpoint\")\n",
    "if not endpoint:\n",
    "    raise RuntimeError(\"endpoint not found in environment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ca0c0",
   "metadata": {},
   "source": [
    "Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb00555",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment = deployment,\n",
    "    api_version = api_version,\n",
    "    api_key = subscription_key,\n",
    "    azure_endpoint = endpoint,\n",
    "    # temperature=0,\n",
    "    # max_tokens=None,\n",
    "    # timeout=None,\n",
    "    # max_retries=2,\n",
    "    # # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc12907e",
   "metadata": {},
   "source": [
    "Test one message and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48ac29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response: content=\"J'adore programmer.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 31, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_7a53abb7a2', 'id': 'chatcmpl-BgGFLcdnQU94bLNr6eyKrtOq2SWSw', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--bff78c8a-0172-4f74-9eff-cb93dcc3702e-0' usage_metadata={'input_tokens': 31, 'output_tokens': 5, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "J'adore programmer.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant that translates English to French. Translate the user sentence.\"),\n",
    "    (\"human\", \"I love programming.\")\n",
    "]\n",
    "\n",
    "# call LLM test\n",
    "ai_msg = llm.invoke(messages)\n",
    "\n",
    "print(\"AI Response:\", ai_msg)\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6476f",
   "metadata": {},
   "source": [
    "Read initiatives CSV and interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90c8e7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   initiative_id                                              title  \\\n",
      "0         304233             Aprova o Orçamento do Estado para 2025   \n",
      "1         284017  Procede à interpretação autêntica do n.º 2 do ...   \n",
      "2         314619  Aprova, para ratificação, as emendas ao Acordo...   \n",
      "3         304313  Pela responsabilização do Estado na alocação d...   \n",
      "4         304312  Assegura a execução, na ordem jurídica interna...   \n",
      "\n",
      "                                             authors                   type  \\\n",
      "0                                            Governo        Proposta de Lei   \n",
      "1                                            Governo        Proposta de Lei   \n",
      "2                                            Governo  Proposta de Resolução   \n",
      "3  Assembleia Legislativa da Região Autónoma da M...        Proposta de Lei   \n",
      "4                                            Governo        Proposta de Lei   \n",
      "\n",
      "                                                 url  \n",
      "0  http://app.parlamento.pt/webutils/docs/doc.pdf...  \n",
      "1  http://app.parlamento.pt/webutils/docs/doc.pdf...  \n",
      "2  http://app.parlamento.pt/webutils/docs/doc.pdf...  \n",
      "3  http://app.parlamento.pt/webutils/docs/doc.pdf...  \n",
      "4  http://app.parlamento.pt/webutils/docs/doc.pdf...  \n"
     ]
    }
   ],
   "source": [
    "file_url = \"./data/processed/1. initiatives.csv\"\n",
    "df = pd.read_csv(file_url)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499941fc",
   "metadata": {},
   "source": [
    "Prepare the LangChain agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3cde10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(llm=llm, df=df, agent_type=\"tool-calling\", verbose=True, allow_dangerous_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf4fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': 'len(df)'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m1397\u001b[0m\u001b[32;1m\u001b[1;3mThere are 1,397 rows in the dataframe.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Agent Response: There are 1,397 rows in the dataframe.\n"
     ]
    }
   ],
   "source": [
    "agent_response = agent.invoke(\"How many rows are there?\")\n",
    "print(); print(\"Agent Response:\", agent_response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0a48a",
   "metadata": {},
   "source": [
    "Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45923c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_INSTRUCTIONS = \"\"\"\n",
    "You are an AI assistant with knowledge of legislative initiatives from the Portuguese Parliament.\n",
    "Each initiative has the following details: initiative_id, title, authors, type, and url.\n",
    "\n",
    "**Guidelines**:\n",
    "- Only mention the URL as a source if and only if the user asks about or references a specific initiative (e.g., by title, type, or ID).\n",
    "- Interpret the field authors with nuance: it may refer to political parties, the Government, parliamentary groups, individual deputies or others.\n",
    "- The type should be interpreted and presented in Portuguese from Portugal (pt-PT). Translate or explain types if necessary when answering in English.\n",
    "- Always answer in the same language the user uses (European Portuguese or English).\n",
    "\n",
    "Your **goal** is to provide accurate, clear, and context-aware information about the initiatives.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_REASONING = \"\"\"\n",
    "- **ALWAYS** before giving the Final Answer, try another method.\n",
    "Then reflect on the answers of the two methods you did and ask yourself if it answers correctly the original question.\n",
    "If you are not sure, try another method.\n",
    "\n",
    "- If the methods tried do not give the same result, reflect and try again until you have two methods that have the same result.\n",
    "- If you still cannot arrive to a consistent result, say that you are not sure of the answer.\n",
    "- If you are sure of the correct answer, create a beautiful and thorough response using Markdown.\n",
    "\n",
    "- **DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE, ONLY USE THE RESULTS OF THE CALCULATIONS YOU HAVE DONE**.\n",
    "- **ALWAYS**, as part of your \"Final Answer\", explain how you got to the answer on a section that starts with: \"\\n\\nExplanation:\\n\".\n",
    "In the explanation, mention the column names that you used to get to the final answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7e7f415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[df['authors'] == 'Governo'].shape[0]\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m35\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df['authors'].value_counts().get('Governo', 0)\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m35\u001b[0m\u001b[32;1m\u001b[1;3m**Final Answer:**\n",
      "\n",
      "Foram registradas 35 iniciativas da responsabilidade do Governo.\n",
      "\n",
      "**Explanation:**\n",
      "Para determinar o número de iniciativas do Governo, utilizei a coluna **authors** e contei quantas vezes o termo \"Governo\" aparece nessa coluna. A função `value_counts()` e um filtro específico foram utilizados, confirmando que o total é de 35 iniciativas.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "---\n",
      "Agent Response\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Final Answer:**\n",
       "\n",
       "Foram registradas 35 iniciativas da responsabilidade do Governo.\n",
       "\n",
       "**Explanation:**\n",
       "Para determinar o número de iniciativas do Governo, utilizei a coluna **authors** e contei quantas vezes o termo \"Governo\" aparece nessa coluna. A função `value_counts()` e um filtro específico foram utilizados, confirmando que o total é de 35 iniciativas."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "QUESTION = \"Quantas iniciativas foram da responsabilidade do governo?\" \n",
    "\n",
    "agent_response = agent.invoke(PROMPT_INSTRUCTIONS + PROMPT_REASONING + QUESTION)\n",
    "print(); print(\"---\"); print(\"Agent Response\"), print()\n",
    "display(Markdown(agent_response[\"output\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
